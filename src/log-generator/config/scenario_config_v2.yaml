manual_mode:
  enabled: false
  scenarios_to_run: ["upi_happy_flow", "http_circuit_breaker",
                     "storage_warning", "storage_severe",
                     "kafka_lag", "kafka_failure",
                     "k8s_cluster_health", "k8s_autoscaling",
                     "kubernetes_node_warning", "docker_restart_warning",
                     "container_crash_loop",
                     "ddos_attack", "auth_token_expiry",
                     "nosql-cluster-fatigue", "nosql-cluster-healthy",
                     "rdbms-cluster-fatigue", "rdbms-cluster-healthy",
                     "network_latency", "packet_loss"]  # e.g. ["upi_happy_flow", "kafka_lag"]

dynamic_fields:
  enable_ip: true
  enable_latency: true
  enable_lag: true
  enable_disk_quota: true
  enable_user_id: true
  enable_trace_id: true
  include_user_agent: true
  pod_old: true
  pod_new: true
  replicas_before: true
  replicas_after: true
  payment_amount: true

scenarios:

  - id: upi_happy_flow
    type: happy_path
    weight: 800
    enabled: true
    flow: [api-gateway, user-service, kyc-service, upi-router, payment-service, transaction-engine, api-gateway]
    log_level: INFO
    ai_reasoning: false
    correlated_logs:
      - api-gateway: "Request received from {ip_address} for {api_endpoint} | user-agent=Mozilla/5.0"
      - user-service: "User profile {user_id} fetched successfully"
      - kyc-service: "KYC status verified for user {user_id}"
      - metrics-server: "CPU usage on pod {pod_old} exceeded 60%"
      - confirmation-service: "User confirmation received from {user_id}"
      - pin-validation-service: "User PIN validated successfully for {user_id}"
      - upi-router: "Routing payment request to bank PSP"
      - payment-service: "Payment of INR {payment_amount} initiated for user {user_id}"
      - rdbms: "INSERT INTO transactions (trace_id, user_id, amount) VALUES ({trace_id}, {user_id}, {payment_amount});"
      - nosql: "Redis::SET user:{user_id}:txn_status = 'success'"
      - transaction-engine: "Transaction logged successfully for trace_id {trace_id}"
      - api-gateway: "Response sent to client with status 200"
      - hpa-controller: "Scaling deployment {service_name} from {replicas_before} to {replicas_after} replicas in namespace fintech-prod"
      - kubelet: "New pod {pod_new} created successfully"

  - id: http_circuit_breaker
    type: error_path
    weight: 3
    enabled: true
    flow: [api-gateway, user-service, upi-router]
    error_at: upi-router
    log_level: [WARN, ERROR]
    ai_reasoning: true
    correlated_logs:
      - user-service: "User session valid for user {user_id}"
      - upi-router: "HTTP 502 - socket closed by peer"
      - api-gateway: "Circuit breaker tripped for upi-router (latency {latency_ms})"
      - api-gateway: "Retry attempt logged for payment"

  - id: storage_warning
    type: storage_degradation
    weight: 0.5
    enabled: true
    flow: [storage-engine, disk, db-node, api-gateway]
    log_level: [WARN]
    ai_reasoning: true
    correlated_logs:
      - storage-engine: "Disk quota at {disk_quota} on {disk_name}"
      - rdbms-cluster: "Replica postgres-{replica_id} lag at {replica_lag}ms (threshold: 1000ms)"
      - rdbms-storage: "Write I/O bottleneck detected on primary (disk latency: {disk_latency}ms) [E_RDB_IO_SLOW]"
      - rdbms-monitor: "Spike in long-running queries on node postgres-{replica_id}"
#      - db-node: "Replica lag increased to {lag_ms} on db-node-2"
      - api-gateway: "Transaction delay noticed due to slow write acknowledgement"

  - id: storage_severe
    type: storage_failure
    weight: 0.5
    enabled: true
    flow: [storage-engine, disk, db-node, api-gateway]
    log_level: [WARN, ERROR]
    ai_reasoning: true
    correlated_logs:
      - storage-engine: "Disk quota critical at {disk_quota} on {disk_name} [E_IO_DISK_95]"
      - db-node: "Write failure due to disk I/O saturation (latency {latency_ms}) [E_DB_WRITE_TIMEOUT]"
      - api-gateway: "HTTP 503 Service Unavailable due to downstream failure"

  - id: kafka_lag
    type: infra_warning
    weight: 0.3
    enabled: true
    flow: [kafka-broker, kafka-consumer]
    log_level: [WARN]
    ai_reasoning: true
    correlated_logs:
      - kafka-broker: "Lag observed: {lag_ms}ms in topic topic-upi-events"
      - kafka-consumer: "Backpressure building on consumer group payment-handler"

  - id: kafka_failure
    type: infra_error
    weight: 0.2
    enabled: true
    flow: [kafka-broker, kafka-consumer]
    log_level: [WARN, ERROR]
    ai_reasoning: true
    correlated_logs:
      - kafka-broker: "Publish failure on topic topic-upi-events after 3 retries"
      - kafka-consumer: "Consumer timeout - backlog too large (lag: {lag_ms})"

  - id: k8s_cluster_health
    type: cluster_health
    weight: 170
    enabled: true
    flow: [k8s-master, scheduler, kubelet, metrics-server]
    log_level: [INFO]
    ai_reasoning: false
    correlated_logs:
      - k8s-master: "All nodes report Ready. Control plane healthy."
      - scheduler: "No pending pods in queue. Scheduler idle."
      - kubelet: "All 37 pods running and healthy"
      - metrics-server: "Cluster CPU usage: 43%. Memory usage: 62%"

  - id: k8s_autoscaling
    type: cluster_scaling
    weight: 20
    enabled: true
    flow: [metrics-server, hpa-controller, kubelet]
    log_level: [INFO, WARN]
    ai_reasoning: true
    correlated_logs:
    - metrics-server: "CPU usage on pod {pod_old} exceeded 80%"
    - hpa-controller: "Scaling deployment {service_name} from {replicas_before} to {replicas_after} replicas"
    - kubelet: "New pod {pod_new} created successfully in namespace fintech-prod"

  - id: kubernetes_node_warning
    type: infra_warning
    weight: 2
    enabled: true
    flow: [kubelet, scheduler, node]
    log_level: [WARN]
    ai_reasoning: true
    correlated_logs:
      - kubelet: "Evicting pod [upi-router] due to memory pressure on node [node-5]"
      - scheduler: "Pod [upi-router] rescheduled to node-2"
      - node: "Node [node-5] memory usage: 95%"

  - id: docker_restart_warning
    type: container_warning
    weight: 2
    enabled: true
    flow: [docker-daemon, kubelet]
    log_level: [WARN]
    ai_reasoning: true
    correlated_logs:
      - docker-daemon: "Container payment-service exited unexpectedly. Exit Code 137"
      - kubelet: "Restarting payment-service pod due to unexpected termination"

  - id: container_crash_loop
    type: infra_error
    weight: 1
    enabled: true
    flow: [docker-daemon, container-runtime]
    log_level: [ERROR]
    ai_reasoning: true
    correlated_logs:
      - docker-daemon: "Container [kyc-service] exited with code 137 (OOMKilled)"
      - container-runtime: "Restarting container [kyc-service] (crash loop detected)"

  - id: ddos_attack
    type: security_warning
    weight: 0.3
    enabled: true
    flow: [api-gateway, security-engine]
    log_level: [WARN]
    ai_reasoning: true
    correlated_logs:
      - api-gateway: "Multiple requests received from {ip_address} (possible anomaly)"
      - security-engine: "Spike in failed requests from subnet 192.168.0.*"

  - id: auth_token_expiry
    type: security_error
    weight: 0.3
    enabled: true
    flow: [auth-service, api-gateway]
    log_level: [INFO, WARN, ERROR]
    ai_reasoning: true
    correlated_logs:
      - auth-service: "Session expired for user {user_id}"
      - api-gateway: "HTTP 401 Unauthorized access attempt"

  - id: network_latency
    type: network_warning
    weight: 0.4
    enabled: true
    flow: [service-router, metrics-server, upi-router]
    log_level: [WARN]
    ai_reasoning: true
    correlated_logs:
      - service-router: "Latency of {latency_ms}ms observed to PSP endpoint {ip_address}"
      - metrics-server: "CPU usage on pod {pod_old} exceeded 75%"
      - upi-router: "Retrying connection to {ip_address}"

  - id: packet_loss
    type: network_error
    weight: 0.2
    enabled: true
    flow: [service-router, upi-router]
    log_level: [WARN, ERROR]
    ai_reasoning: true
    correlated_logs:
      - service-router: "Packet loss detected to {ip_address} - retries exhausted"
      - upi-router: "Downstream unresponsive - tripping circuit breaker"

  - id: rdbms-cluster-healthy
    weight: 2
    correlated_logs:
      - rdbms-cluster: "Primary DB node postgres-1 up and healthy"
      - rdbms-cluster: "All 3 replicas are in sync with primary (replication lag < 100ms)"
      - rdbms-monitor: "Query throughput steady at {qps} QPS across cluster"

  - id: rdbms-cluster-fatigue
    weight: 1
    correlated_logs:
      - rdbms-cluster: "Replica postgres-{replica_id} lag at {replica_lag}ms (threshold: 1000ms)"
      - rdbms-storage: "Write I/O bottleneck detected on primary (disk latency: {disk_latency}ms) [E_RDB_IO_SLOW]"
      - rdbms-monitor: "Spike in long-running queries on node postgres-{replica_id}"

  - id: nosql-cluster-healthy
    weight: 2
    correlated_logs:
      - nosql-cluster: "Primary node mongo-0 healthy. Replication set active."
      - nosql-cluster: "All shards balanced across 3 nodes"
      - nosql-monitor: "In-memory cache hit ratio: {cache_hit_ratio}%"

  - id: nosql-cluster-fatigue
    weight: 1
    correlated_logs:
      - nosql-cluster: "Replica set member mongo-{replica_id} syncing slow (replication lag: {replica_lag}ms)"
      - nosql-monitor: "Write throughput dropped below threshold on shard-{shard_id} [E_NOSQL_WRITE_LAG]"
      - nosql-cluster: "Auto-resync triggered for node mongo-{resync_node}"